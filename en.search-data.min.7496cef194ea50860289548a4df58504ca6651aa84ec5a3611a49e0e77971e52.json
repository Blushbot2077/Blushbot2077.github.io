[{"id":0,"href":"/post/computonal_mechanism/","title":"Computational mechanism","section":"Posts","content":"🐽宝的手记\n三、RW 与贝叶斯模型的结合：POMDP # POMDP (partially observable Markov decision process, 部分可观察的马尔科夫决策过程), 源自 MDP，因此具备强化学习的属性。\n然而，在真实的社会情境中, 人们不能准确掌握环境的真实的状态(i.e., 他人的道德品质), 仅能通过感官获得一部分能反映状态的观测值(i.e., 外显的行为), 此时人们利用观测值形成对真实状态的概率估计, MDP 则变成POMDP。\n包含的变量：\n人们获得的观测值：Z\n状态先验条件下的观测值似然函数：O\nPOMDP 具备贝叶斯属性：\n在 POMDP 中，人们根据状态的后验信念，也就是信念状态（belief state）做出决策，而信念状态的更新则基于贝叶斯信息更新方式。\n后验信念 = (先验信念 × 似然度) / 证据\n先验信念：考虑任何新的证据之前，我们对事件或假设的信念或概率分布。\n似然度：在给定新的数据或观察的条件下，事件或假设成立的概率。\n证据：观察到的数据或证据的概率。\nIPOMDP：（Interactive POMDP），与 POMDP 相比，对状态的估计还包括了对他人模型的估计。\n实现计算模型相关的toolbox # hBayesDM toolbox (R, python) HGF toolbox (Matlab) VBA toolbox (Matlab) CBM toolbox (Matlab) 四、社会学习的神经机制 # "},{"id":1,"href":"/post/preprocessing/","title":"fMRI脑成像预处理(SPM12 Preprocessing)","section":"Posts","content":"Convert, FieldMap , 以及Preproceesing\nConvert DICOM - NIfTI # 两种方法: SPM12 DICOM import 和 MRIcroGL(dcm2niix)\n直接使用 SPM12 转换非常简单，但缺点是无法看到 DICOM 文件的原始数据（比如TR，TE），可能会对 Fieldmap 校正选择参数带来一些困难。而使用 MRIcroGL 则可以额外生成保留原数据的 json 文件。因此这里主要说明 MRIcroGL 的操作方法。\nMRIcroGL is also used for visualizing imaging data, especially group-level results. 但目前只用来转换成 NIfTI 文件.\n以下内容参考了Andysbrainbook.\n安装 MRIcroGL # 安装后进入软件,菜单栏选中import-\u0026gt;Convert DICOM to NIfTI,会看到如下界面:\nOutput Filename：默认是格式化运算符%f_%p_%t_%s,鼠标停留在名称上会有每个变量的具体说明,可以根据需要修改转换后输出的名称。\nOutput Derictiory：输出路径，默认与DICOM文件在同一个文件夹。\nOutput Format：输出格式，默认是compressed NIfTI. 但请注意,SPM无法打开压缩的文件（AFNI和FSL都可以打开），建议手动选择uncompressed NIFTI。\nCreate BIDS Sidecar：该选项会创建一个包含原DICOM数据的Javascript Object Notation (.json)文件，包括slice-timing, slice order, the repetition time, echo time 等等。其中，Echo time 是 Fieldmap 时很重要的一个参数。\nConverting the DICOM Files using MRIcroGL # 可以通过鼠标拖拽或者Select Folder to Convert 按钮选择想要转换的DICOM文件夹，右侧窗口会显示转换完成。\nRunning DICOM to NIFTI from the Command Line # （还没使用过）\nFieldMap 校正 # FieldMap 校正是指，对成像进行动态或静态的畸变校正。\nSPM12 中使用 Fieldmap toolbox 进行 Fieldmap 校正。\n两个步骤：\nCalculate，计算 VDM（voxel displacement map） Apply，使用 VDM 对成像进行校正 几个我用到的关键参数：\nCalculate VDM. Echo time：需要手动输入 Magnitude Image 和 Phase Image 的 short TE 和 long TE。(i.e.,[4.92 7.38])\nMagnitude Image: 有多个时选择 TE 更小的，有更好的信号强度。\nPhase Image：信号和radiofrequency pulse的相位。\nMask brain: 选择是否 mask brain。如果选择 masking，Magnitude Image 会用来生成一个 brain mask。\nBlip direction：相位编码方向与 Y 方向（从后脑勺往前额）的关系。+ve 为1，-ve 为-1。\nEPI-based filed map: 是否基于 EPI 获得的 Fieldmap，基于 EPI 的fieldmap 相当于是在扭曲的空间里获得了场图，因此生成 VDM 将会被调整。\nuflags: phase unwrapping 和 field map 处理的不同选项。加权平滑。\nmflags：segmentation 和创建 brain mask 的不同选项。使用 T1 对变形的 EPI 进行校正。\nVDM filename extension：生成的 VDM 文件的前缀，s。\nWrite unwarped EPI?: 导出校正后的 EPI，前缀是 u。(仅用来quality control of correction)\n计算 VDM 需要 MI 和 PI 这两个参数\nApply VDM. images:需要进行场图校正的 EPI。【代码写法】\nField map (vdm*file):需要应用的VDM，一个以vdm开头的文件。\nP.S. 所有过程都可以以 batch code 方式批量操作。\n校正后的EPI文件的前缀是wu，表示\u0026quot;warped and unwarped\u0026quot;。\n校正后的EPI文件保存在与输入EPI图像相同的路径下。\nRealignment # 运动校正，修正EPI的位移\nRealign \u0026amp; Unwarp（运动校正和磁场畸变校正）\nUnwarp 和 Field map\n都是用于磁场畸变校正的方法，但具有不同的原理和实施步骤，具体根据实验的需要选用。\nUnwarp（畸变校正）：Unwarp方法是基于图像处理的技术，通过图像重采样和插值来校正图像畸变。它依赖于相邻时间点的fMRI图像信息。Unwarp方法通常需要额外的参考数据（例如，额外的fMRI序列）来估计磁场畸变的模型。\nField Map（场图法）：Field map方法是基于磁场测量的技术，通过测量磁场变化来估计和校正磁场畸变。它依赖于额外的磁场映射扫描数据。\nCoregistration # 将T1登陆到EPI(变换、计算处理) 有三种变换方式:Affine(平移+旋转的刚体变换),Stretching(保持一个方向不变移动其他方向),Shearing(扩大+缩小变形)\nEstimate：estimate用于估计将源图像（EPI）与参考图像（T1）对齐所需的变换参数。这些变换参数描述了源图像与参考图像之间的平移（translation）和旋转（rotation）关系，以使它们在相同的坐标空间中对齐。estimate步骤不会对图像进行重采样。\nReslice：reslice用于根据先前估计的变换参数对源图像 EPI 进行重采样，以使其与参考图像 T1 在空间上对齐。通过重采样，源图像 EPI 的像素将根据变换参数重新分布和插值，使其与参考图像 T1 的空间坐标一致。在后续分析时，EPI 与 T1 就可以在相同的空间坐标系下进行对应。\nEstimate \u0026amp; Reslice：estimate \u0026amp; reslice 是将上述两个步骤合并为一个步骤的选项。一次性完成 estimate 和 reslice。\n一些我用到的参数：\nReference Image: 其他图像配准时的对照. Batch 操作时一般选择 Realign: Estimate \u0026amp; Resllice: Mean image，即上一步Realign过后生成的 Mean image。（我的分析中跳过了Realignment，直接用了 T1 ）\nSource Image: 应基于参比图像进行处理的图像。我的分析中使用了EPI（f 开头）\nEstimation options 中的参数：\nCost Function: Coregistration 涉及到最大化或最小化目标函数的参数（更好的Coregistation）常用的目标函数有：Mutual Information（mi），Normalized Mutual Information（nmi），Sum of Squared Differences（ssd），Correlation Ratio（corr_ratio）. （我的分析用了mni）\nSeparation: The average distance between sampled points (mm). 也就是源图像和参考图像之间的初始平移和旋转变换的初始步长。较大的Separation值适用于粗略的初始对齐，较小的Separation值适用于较精细的初始对齐。可以是一个vector，允许粗略的coregistration过后进行精细的coregsitration。i.e.,[4,2]\nTolerances: 指控制配准算法的终止条件。这些参数指定了在搜索对齐参数空间时用于终止搜索的阈值或容差值。包括Translation Tolerances（平移容差）, Rotation Tolerances（旋转容差）, Scale Tolerances（缩放容差）, Affine Tolerances（仿射容差）. 通常情况下，建议开始时使用较大的容差值进行初始对齐，然后逐渐减小容差值以提高对齐的精度。\nFWHM: FWHM参数定义了高斯滤波器的半高全宽（mm），用于指定 fMRI 图像的平滑程度。较小的FWHM值表示较小的滤波器，产生较少的平滑效果；较大的FWHM值表示较大的滤波器，产生更显著的平滑效果。较小的FWHM值适用于高分辨率数据和对细节较敏感的分析，但可能会保留更多的噪声。较大的FWHM值适用于低分辨率数据和对噪声较不敏感的分析，但可能会损失一些图像细节。i.e.,[7,7]\nSegmentation # 将T1分解为标准脑6要素,分割后称为 TPM\n相关的参数：\nChannel: 指每个体素（Voxel）在fMRI数据中的观测通道数。通常为1，表示每个体素只有一个观测通道（T1）。\nVolumes: 从已经选择的channel中选择scan。（这里就选择T1 images）\nBias regularisation: 用于对磁共振图像中的偏差进行正则化的参数。偏差通常是由磁场非均匀性或硬件特性引起的亮度变化。通过启用偏差正则化，可以减少这些偏差的影响，提高图像质量。 MR扫描中的intensity variation可能由两种可能引起：MR扫描物理原理引起的偏差伪影（bias artifact），或者不同组织的特性。[light regularisation: 0.001]\nBias FWHM: 指定了在偏差校正过程中应用的滤波器的全宽半最大值（Full Width at Half Maximum，FWHM）。较高的FWHM值表示较大的平滑程度，而较低的FWHM值表示较小的平滑程度。该参数控制偏差场的平滑程度。[60 mm cutoff]\nwirte：channel.write = [0 1]表示保存白质和灰质通道的分割结果。（Channel 0：gray matter, Channel 1：white matter, Channel 2：cerebrospinal fluid.）\ntissue\nTissue probability map: Segmentation生成文件在T1文件夹里，c1+T1文件名.nii\nNormalisation # EPI标准化\n为了把 Coregistration 过后的图像和 MNI 标准脑 TPM 重合而进行计算\nSmoothing # EPI空间平滑化\n通过应用高斯滤波器，对fMRI图像进行空间平滑处理。平滑处理有助于减少噪声和局部变异，提高信号与噪声的比值，并提升数据的统计可靠性。\n空间上幅的表示方法:半值全幅(FWHM,Full Width at Half Maximum)\n半值全幅(FWHM),指从 peak 开始高度一半地方的宽度. FWHM的值一般是voxel的2-3倍,不过在评价杏仁核这样的小结构时,也用1.5倍这样的小数值. FWHM越大,整体的功能画像就会越模糊(因为FWHM越大,意味着图像和平均的相邻voxel相关度变高).\n我自己用到的顺序 # Day1:\nConvert DICOM to NIfTI\nCoregister EPI to T1 (by BatchCoreg.m)\nFieldmap process (by BatchCalVDM.m)\nCoregister fieldmap-corrected EPI to T1\nSegmentation（x）\nSmooth　555\nDay2\nConvert DICOM to NIfTI\nCoregister EPI to T1 (by BatchCoreg.m)\nFieldmap process (by BatchCalVDM.m)\nCoregister fieldmap-corrected EPI to T1\nSegmentation\nNormalisation\nSmooth\nNormalisation　is used to compare d1 and d2 data.\nModel construction\nEstimation\nconstruct contrasts\naverage among subjects (only D2)\nReference # SPM12 Manual\nSPM 中文初学者指南\n暂时存一下\n"},{"id":2,"href":"/about/","title":"About Hugo","section":"健康第一!","content":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\nhttps://github.com/yuin/goldmark https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub.\n"},{"id":3,"href":"/archives/","title":"Archives","section":"健康第一!","content":"You can change archives page details above.\nKeep this file saft to ensure Hugo generate the archives page.\n"},{"id":4,"href":"/search/","title":"Search","section":"健康第一!","content":"You can change search page details above.\nKeep this file saft to ensure Hugo generate the search page.\n"}]